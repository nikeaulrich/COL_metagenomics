{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1819fc-037e-469e-84da-c4a596fd4981",
   "metadata": {},
   "source": [
    "# Classifying taxonomy COL_032024 seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb3035-5a18-4ffb-beac-8e358851b722",
   "metadata": {},
   "source": [
    "## GTDB-Tk\n",
    "https://github.com/Ecogenomics/GTDBTk?tab=readme-ov-file \\\n",
    "GTDB-Tk identifies a core set of genes in the MAG, and use these to compute a species phylogeny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799989d-ef75-4d52-b5fb-d58943b427d4",
   "metadata": {},
   "source": [
    "**The gtdb reference database needs 100GB space so do not create conda env in /home directory. Either create the env in /work or /scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0fd24-12a9-4754-a841-757966ebb912",
   "metadata": {},
   "source": [
    "I used this opportunity to create a /scratch directory with this documentation: https://docs.unity.rc.umass.edu/documentation/managing-files/hpc-workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5f8d3-550c-4d89-99a2-76982e598922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create scratch directory\n",
    "ws_allocate gtdb 30\n",
    "\n",
    "#FOR LATER:to release scratch space when you don't need it anymore\n",
    "ws_release gtdb"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1631a38-e14c-4061-a88e-7de6f570b912",
   "metadata": {},
   "source": [
    "Info: creating workspace.\n",
    "/scratch3/workspace/nikea_ulrich_uml_edu-gtdb\n",
    "remaining extensions  : 3\n",
    "remaining time in days: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae9459-f639-4728-916c-1dfe393feb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION of gtdbtk in /scratch\n",
    "cd /scratch3/workspace/nikea_ulrich_uml_edu-gtdb\n",
    "module load conda/latest\n",
    "mkdir -p /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs\n",
    "conda create --prefix /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy python=3.8\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "conda install -c conda-forge -c bioconda gtdbtk=2.4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b481da-c22c-4400-894a-cb20cbb97379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda package is bundled with a script that will automatically download, and extract the GTDB-Tk reference data, simply run:\n",
    "download-db.sh\n",
    "#This will take awhile -- massive database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ec254-7a0c-4c37-b2cd-8d714066e2dc",
   "metadata": {},
   "source": [
    "https://ecogenomics.github.io/GTDBTk/commands/classify_wf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5abdc-e9c8-4b39-b6d0-c4de9a7b61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=150G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/mcav/slurm-gtdb_taxonomy-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "\n",
    "# Set parameters\n",
    "SAMPLENAME=\"mcav\"\n",
    "BINPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/binning/${SAMPLENAME}/${SAMPLENAME}_DASTool_bins\"\n",
    "OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/${SAMPLENAME}\"\n",
    "mkdir -p $OUTDIR\n",
    "\n",
    "#Run gtdb-tk\n",
    "gtdbtk classify_wf -x fa --skip_ani_screen \\\n",
    "--genome_dir $BINPATH/ --out_dir $OUTDIR/gtdb_out\n",
    "\n",
    "#This will process all genomes in the directory <my_genomes> using both bacterial and archaeal marker sets and place the results in <output_dir>.\n",
    "#Genomes must be in FASTA format (gzip with the extension .gz is acceptable)\n",
    "\n",
    "# JOB-ID:\n",
    "# bash script file name: /nikea/COL/bash_scripts/Col_gtdb_taxonomy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29742cf4-1ba4-4146-96fd-90287f3df9c3",
   "metadata": {},
   "source": [
    "dlab job ID: 27123105 \\\n",
    "mcav job ID: 27159595 \\\n",
    "ofav job ID: 27159884 \\\n",
    "pstr job ID: 27159918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ed6f4-5cf1-4da3-a145-5bf57c6fbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=100G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/mcav/slurm-itol-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "\n",
    "SAMPLENAME=\"mcav\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/${SAMPLENAME}/gtdb_out/classify\"\n",
    "OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/${SAMPLENAME}/gtbd_trees_for_vis\"\n",
    "mkdir -p $OUTDIR\n",
    "\n",
    "#convert all classify trees to itol readable format\n",
    "gtdbtk convert_to_itol --input $WORKDIR/gtdbtk.bac120.classify.tree.4.tree --output $OUTDIR/itol.gtdbtk.classify.tree.4.tree\n",
    "\n",
    "gtdbtk convert_to_itol --input $WORKDIR/gtdbtk.bac120.classify.tree.6.tree --output $OUTDIR/itol.gtdbtk.classify.tree.6.tree\n",
    "\n",
    "gtdbtk convert_to_itol --input $WORKDIR/gtdbtk.bac120.classify.tree.8.tree --output $OUTDIR/itol.gtdbtk.classify.tree.8.tree\n",
    "\n",
    "gtdbtk convert_to_itol --input $WORKDIR/gtdbtk.backbone.bac120.classify.tree --output $OUTDIR/itol.gtdbtk.backbone.classify.tree\n",
    "\n",
    "# JOB-ID:27211859\n",
    "# bash script file name: /nikea/COL/bash_scripts/Col_gtdb2itol_taxonomy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21105a-787b-42f5-a0be-a0bf2f4888a9",
   "metadata": {},
   "source": [
    "*This above script could be included in the inital gtdbtk script for next use*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0932be-0740-4028-a93f-9f57933ddf9d",
   "metadata": {},
   "source": [
    "copied all bins to: /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c4aef-6f88-43b2-8700-c243ae867c45",
   "metadata": {},
   "source": [
    "putting all the bins (from all 4 coral species) together so that they are in the same multiple sequence alignment. Added the species name in front to know what species the bin is from. \\\n",
    "will run gtdb-tk again and then take that msa to iqtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f17516-8034-4426-901a-e4fa4729fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=150G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/slurm-gtdb_taxonomy-all-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "\n",
    "# Set parameters\n",
    "BINPATH='/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/bins'\n",
    "OUTDIR='/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/'\n",
    "\n",
    "#Run gtdb-tk\n",
    "gtdbtk classify_wf -x fa --skip_ani_screen \\\n",
    "--genome_dir $BINPATH/ --out_dir $OUTDIR/gtdb_allbins_out\n",
    "\n",
    "#This will process all genomes in the directory <my_genomes> using both bacterial and archaeal marker sets and place the results in <output_dir>.\n",
    "#Genomes must be in FASTA format (gzip with the extension .gz is acceptable)\n",
    "\n",
    "# JOB-ID: 27941759\n",
    "# bash script file name: /nikea/COL/bash_scripts/Col_gtdb_taxonomy_all.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58842cf4-d308-45a7-8aea-d26087bc8015",
   "metadata": {},
   "source": [
    "## IQ-Tree\n",
    "http://www.iqtree.org/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395cbeba-f70d-420d-bfae-1dc0344534a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "conda install -c bioconda iqtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11945a-38a1-48b8-bd4a-2459b56eb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=100G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/slurm-iqtree-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/taxonomy\n",
    "\n",
    "#set parameters\n",
    "MSAPATH='/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/gtdb_allbins_out/align'\n",
    "MSA=\"gtdbtk.bac120.user_msa.fasta.gz\"\n",
    "OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/taxonomy/iqtree\"\n",
    "mkdir -p $OUTDIR\n",
    "\n",
    "cd $OUTDIR\n",
    "\n",
    "#run iqtree\n",
    "iqtree -s $MSAPATH/$MSA -T AUTO -m TEST -alrt 1000 -B 1000 --prefix all_bins\n",
    "\n",
    "# JOB-ID: 27949135\n",
    "# bash script file name: /nikea/COL/bash_scripts/Col_iqtree.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bdeff-0864-425c-955d-ba0372bff28b",
   "metadata": {},
   "source": [
    "## Kraken2 on samples (all seq data)\n",
    "specifically those that have been identified by Jordan in Ushijima lab as containing high antimicrobial activity\n",
    "https://github.com/DerrickWood/kraken2/wiki/Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d85bd4-56e7-4d37-b375-68f8b5151dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "module load conda/latest\n",
    "conda create --prefix /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/kraken2 python=3.8\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/kraken2\n",
    "conda install bioconda::kraken2\n",
    "conda install bioconda/label/cf201901::kraken2\n",
    "\n",
    "#install bracken in the same environment\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/kraken2\n",
    "conda install bracken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f90fe4-d258-4e66-b239-9c7a6853b558",
   "metadata": {},
   "source": [
    "Using the database already downloaded and built in /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/ref_databases/standard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e380f9-bb13-46d9-86c0-f31fb48504a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/kraken2/slurm-kraken-pstr-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/kraken2\n",
    "\n",
    "#db already downloaded and built by Brooke\n",
    "DBNAME=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/ref_databases/standard\"\n",
    "READS=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/pstr/final_reads_filtered\"\n",
    "OUTDIR=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/kraken2\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "SAMPLELIST=\"032024_pstr_sampleids.txt\"\n",
    "\n",
    "THREADS=20\n",
    "KMER_LEN=35 #(default)\n",
    "READ_LEN=150\n",
    "\n",
    "#starting with pstr\n",
    "# classify each set of paired end reads against refseq taxonomic database\n",
    "while IFS= read -r SAMPLEID; do\n",
    "kraken2 --db $DBNAME --threads $THREADS --report $OUTDIR/\"${SAMPLEID}\".kreport2 --report-zero-counts --paired $READS/\"${SAMPLEID}\"_host_removed_R1.tagged_filter.fastq.gz $READS/\"${SAMPLEID}\"_host_removed_R2.tagged_filter.fastq.gz > $OUTDIR/\"${SAMPLEID}\".kraken2\n",
    "if [ $? -eq 0 ]; then\n",
    "        echo \"kraken2 completed successfully for sample: $SAMPLEID\"\n",
    "    else\n",
    "        echo \"kraken2 encountered an error for sample: $SAMPLEID\"\n",
    "        exit 1\n",
    "    fi\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "echo \"Kraken2: All samples processed successfully.\"\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "# JOB-ID: 30883862\n",
    "# bash script file name: /bash_scripts/kraken2-pstr_standard.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fbb77-dea8-4272-b928-74afbbaa3c6f",
   "metadata": {},
   "source": [
    "ran this for the others ofav (30924382), mcav (30992591), and dlab (30993197). I ran these on filtered reads (host, human, and symbionts all removed). I had to repair these reads for megahit assembly but resulted in losing some singleton reads, so opted to just run the filtered reads rather than the repaired reads (keeping as many sequences as possible!)\n",
    "Also ran on just host-removed pstr (30884134) but becuase kraken2 seemed to identify lots on the human/sym filtered reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c5716-7961-44e1-9723-73f9cf7fa7dc",
   "metadata": {},
   "source": [
    "## Bracken\n",
    "https://github.com/jenniferlu717/Bracken/blob/master/README.md \\\n",
    "abundance estimation from kraken2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b896f8-1aef-44d2-80a3-42fdbbcbbce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/bracken/slurm-bracken-pstr-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/kraken2\n",
    "\n",
    "DBNAME=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/ref_databases/standard\"\n",
    "OUTDIR=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/kraken2/bracken\"\n",
    "mkdir -p $OUTDIR\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL\"\n",
    "SAMPLELIST=\"032024_pstr_sampleids.txt\"\n",
    "\n",
    "THREADS=20\n",
    "KMER_LEN=35 #(default)\n",
    "READ_LEN=150\n",
    "\n",
    "# Generate bracken database - just do once\n",
    "#bracken-build -d ${DBNAME} -t ${THREADS} -k ${KMER_LEN} -l ${READ_LEN} \n",
    "\n",
    "#${KRAKEN_DB}`  = location of the built Kraken 1/Kraken 2/KrakenUniq database\n",
    "#${THREADS}`    = number of threads to use with Kraken and the Bracken scripts\n",
    "#${KMER_LEN}`   = length of kmer used to build the Kraken database \n",
    "    #Kraken 1/KrakenUniq default kmer length = 31\n",
    "    #Kraken 2 default kmer length = 35\n",
    "    #Default set in the script is 35. \n",
    "#${READ_LEN}`   = the read length of your data e.g., if you are using 100 bp reads, set it to `100`. \n",
    "#need taxo.k2d, hash.k2d, and opts.k2d. in kraken2 database\n",
    "\n",
    "# Abundance Estimation with Bracken\n",
    "#trying on just pstr first\n",
    "KRAKENFILES=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/kraken2\"\n",
    "LEVEL=\"S\"\n",
    "\n",
    "while IFS= read -r line; do\n",
    "    # Execute bracken command for each file\n",
    "    bracken -d \"$DBNAME\" -i $KRAKENFILES/\"$line\".kreport2 -o $OUTDIR/\"${line%.kreport2}_$LEVEL.bracken\" -r \"$READ_LEN\" -l \"$LEVEL\"\n",
    "if [ $? -eq 0 ]; then\n",
    "        echo \"bracken completed successfully for sample: $SAMPLEID\"\n",
    "    else\n",
    "        echo \"bracken encountered an error for sample: $SAMPLEID\"\n",
    "        exit 1\n",
    "    fi\n",
    "    done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "    \n",
    "conda deactivate\n",
    "\n",
    "#${SAMPLE}.kreport - the kraken report generated for a given dataset\n",
    "#{BRACKEN_OUTPUT_FILE}.bracken - the desired name of the output file to be generated by the code\n",
    "#The following optional parameters may be specified:\n",
    "    #${LEVEL} - Default = 'S'. This specifies that abundance estimation will calculate estimated reads for each species. Other possible options are K (kingdom level), P (phylum), C (class), O (order), F (family), and G (genus).\n",
    "    #${THRESHOLD} - Default = 10. For species classification, any species with <= 10 (or otherwise specified) reads will not receive any additional reads from higher taxonomy levels when distributing reads for abundance estimation. \n",
    "    #If another classification level is specified, thresholding will occur at that level.\n",
    "\n",
    "# JOB-ID: 31001829\n",
    "# bash script file name: /bash_scripts/bracken-pstr.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9169d-ba08-4ff8-b8fb-91aa692af96c",
   "metadata": {},
   "source": [
    "ran this on all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaad57c-eac6-4a15-a203-2d835bee7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To merge tables, I downloaded combine_bracken_outputs.py and put in the same directory as the bracken output\n",
    "python combine_bracken_outputs.py --files *.bracken --output 032024_COL_SAN_merged_bracken_species.txt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
