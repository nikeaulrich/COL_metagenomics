{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680d010c-f977-4bd8-b40d-18dc9a8de3b6",
   "metadata": {},
   "source": [
    "# Gene annotation and mapping for per sample information COL_032024 seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999be4c8-4886-404d-9595-72e14766fa28",
   "metadata": {},
   "source": [
    "Annotating metagenomic assembled genomes with MetaCerberus:https://github.com/raw-lab/MetaCerberus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6601c9f-7a07-4263-b871-63fd11636ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION\n",
    "#using scratch workspace I created in 4Col_taxonomy\n",
    "cd /scratch3/workspace/nikea_ulrich_uml_edu-gtdb\n",
    "module load conda/latest\n",
    "conda create --prefix /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/metacerberus -c conda-forge -c bioconda metacerberus -y\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/metacerberus\n",
    "metacerberus.py --setup\n",
    "metacerberus.py --download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6fb04-a961-4911-8f46-10a1b3179416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd6c7e-1f42-4d04-99c4-65c98f5fc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=50G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/mcav/slurm-metacerberus-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/metacerberus\n",
    "\n",
    "#for troubleshooting purposes, copied mcav bins to /scratch3\n",
    "\n",
    "# Set parameters\n",
    "SAMPLENAME=\"mcav\"\n",
    "BINS=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb\"\n",
    "#BINPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/binning/${SAMPLENAME}/${SAMPLENAME}_DASTool_bins\"\n",
    "OUT=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/metacerberus_output\"\n",
    "#OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/${SAMPLENAME}\"\n",
    "#mkdir -p $OUT\n",
    "\n",
    "cd $BINS\n",
    "\n",
    "#metacerberus.py --prodigal metabat2.5.fa --hmm ALL --dir_out $OUT/metabat2.5.fa\n",
    "\n",
    "\n",
    "#this all works fine below, but was hoping to get to the issue with doing indiv. still no dice\n",
    "#make list of bins\n",
    "#ls *.fa > \"$SAMPLENAME\"_bins.txt\n",
    "\n",
    "#run metacerberus\n",
    "#for f in $(cat \"$SAMPLENAME\"_bins.txt) \n",
    "#do\n",
    "  #  echo \"processing $f\"\n",
    "#metacerberus.py --prodigal \"$f\" --hmm ALL --dir_out $OUT/\"$f\"\n",
    "#done\n",
    "    \n",
    "  ##--minscore MINSCORE   Score cutoff for parsing HMMER results [60]\n",
    "  ##--evalue EVALUE       E-value cutoff for parsing HMMER results [1e-09]\n",
    "  ##--remove-n-repeats    Remove N repeats, splitting contigs [False]\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "# JOB-ID:\n",
    "# bash script file name: /nikea/COL/bash_scripts/Col_metacerberus.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d2214-5444-4bbe-a3ee-730cda9311bb",
   "metadata": {},
   "source": [
    "let's try DRAM instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fd9da-37dd-4006-b09e-06b52403dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION\n",
    "wget https://raw.githubusercontent.com/WrightonLabCSU/DRAM/master/environment.yaml\n",
    "module load conda/latest\n",
    "conda env create -f environment.yaml --prefix /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/DRAM\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/DRAM\n",
    "DRAM-setup.py prepare_databases --output_dir DRAM_data #this has a documented issue (broken script in DRAM-setup.py) new version should be coming out in 2025\n",
    "conda env remove -n /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/DRAM\n",
    "#instead let's try installing with bioconda, there's evidence from others that this version has been fixed\n",
    "\n",
    "module load conda/latest\n",
    "conda create --prefix /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/dram\n",
    "conda activate /scratch3/workspace/nikea_ulrich_uml_edu-gtdb/envs/dram\n",
    "conda install -c bioconda dram\n",
    "DRAM-setup.py prepare_databases --output_dir DRAM_data #worked but needs to be in a bash script because of memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b78d9b-bf34-4ee7-93e0-f68c1dc94dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=400G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/DRAM-setup/slurm-metacerberus-%j.out  # %j = job ID  # %j = job ID\n",
    "\n",
    "finish script here if you decide to go with DRAM - maybe eggNOG annotations are the way to go for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d3c38-c868-42f4-bad1-eb8f938f8f65",
   "metadata": {},
   "source": [
    "Map the reads of each sample back to the MAG catalogue and retrieve mapping statistics. This gives you relative abundance information to measure how abundant or rare each bacteria was in each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05af102-92b5-464c-8930-d65e5ddfa196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to install CoverM in the anvi'o environment \n",
    "module load conda/latest\n",
    "conda activate anvio-8\n",
    "conda install -c bioconda coverm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35ef5e-ea71-4b03-8cc1-30891bae891a",
   "metadata": {},
   "source": [
    "## CoverM\n",
    "https://wwood.github.io/CoverM/coverm-genome.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f638e99-0bdd-4bf3-bf36-e73cb03952f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/dlab/slurm-MAG-mapping-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate anvio-8\n",
    "\n",
    "\n",
    "SAMPLENAME=\"dlab\"\n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/repaired\"\n",
    "MAGPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/binning/${SAMPLENAME}/${SAMPLENAME}_DASTool_bins\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/${SAMPLENAME}\"\n",
    "mkdir -p \"$WORKDIR\"\n",
    "MAGDB=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/${SAMPLENAME}/MAG_db\"\n",
    "mkdir -p \"$MAGDB\"\n",
    "XTRAFILES=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/annotation/${SAMPLENAME}\"\n",
    "mkdir -p \"$XTRAFILES\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "SAMPLELIST=\"032024_${SAMPLENAME}_sampleids.txt\"\n",
    "\n",
    "\n",
    "#concatenate MAGs into 1 file to create a MAG database\n",
    "cat $MAGPATH/*.fa > $MAGDB/\"$SAMPLENAME\"_mags.fsa\n",
    "\n",
    "cd $MAGDB\n",
    "#index MAG database with bowtie2\n",
    "bowtie2-build --large-index --threads 11 \"$SAMPLENAME\"_mags.fsa \"$SAMPLENAME\"_index\n",
    "\n",
    "while IFS= read -r SAMPLEID; do\n",
    "    #align reads to your contigs and collects that in a .sam file\n",
    "    bowtie2 --threads 11 -x \"$SAMPLENAME\"_index -1 $READSPATH/\"${SAMPLEID}\"_host_removed_R1.tagged_filter_ready.fastq.gz -2 $READSPATH/\"${SAMPLEID}\"_host_removed_R2.tagged_filter_ready.fastq.gz -S $XTRAFILES/\"${SAMPLEID}\".sam\n",
    "    #make sure to point it to the index not the FIXEDCON file (-x parameter)\n",
    "    \n",
    "    #converts your sam file to a bam file, but its neither sorted nor indexed, so we use an Anvi'O script to do so:\n",
    "    samtools view -F 4 -b -S $XTRAFILES/\"${SAMPLEID}\".sam -o $WORKDIR/\"${SAMPLEID}\"-RAW.bam\n",
    "   \n",
    "    #index and sort your bam file\n",
    "    anvi-init-bam $WORKDIR/\"${SAMPLEID}\"-RAW.bam -o $WORKDIR/\"${SAMPLEID}\".bam\n",
    "    \n",
    "    rm $WORKDIR/\"${SAMPLEID}\"-RAW.bam\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "echo \"Mapping success!\"\n",
    "\n",
    "#extract stats with CoverM\n",
    "coverm genome \\\n",
    "    -b $WORKDIR/ \\\n",
    "    -m relative_abundance \\\n",
    "    --min-covered-fraction 0 \\\n",
    "    -o $WORKDIR/mapping_rate\n",
    "\n",
    "coverm genome \\\n",
    "    -b $WORKDIR/ \\\n",
    "    -m count covered_fraction \\\n",
    "    --min-covered-fraction 0 \\\n",
    "    -o $WORKDIR/count_table\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "#JOB ID: 28168719 (coverm didn't run)\n",
    "#bash script: nikea/COL/bash_scripts/Col_MAG_mapping.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e1b2b-9511-472c-b1d7-b1a3bbf0d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "error: the following required arguments were not provided:\n",
    "  --separator <separator>\n",
    "  --genome-fasta-files <genome-fasta-files>...\n",
    "  --genome-fasta-directory <genome-fasta-directory>\n",
    "  --genome-fasta-list <genome-fasta-list>\n",
    "  --genome-definition <genome-definition>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a0ef9-cce5-45bb-bdca-84592002bc07",
   "metadata": {},
   "source": [
    "added bin identifier to each contig in MAGs (in /scratch3) so that when they are concatenated into 1 MAG database, the MAGs can be identified still"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab25f81-dfe3-4360-b3db-2bddf9ed45fc",
   "metadata": {},
   "source": [
    "made changes and ran again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6554ae2-6bb6-444e-a1e9-177285b31c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/dlab/slurm-MAG-mapping-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate anvio-8\n",
    "\n",
    "\n",
    "SAMPLENAME=\"dlab\"\n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/repaired\"\n",
    "MAGPATH=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/bins/${SAMPLENAME}\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/${SAMPLENAME}\"\n",
    "mkdir -p \"$WORKDIR\"\n",
    "MAGDB=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/annotation/${SAMPLENAME}/MAG_db\"\n",
    "mkdir -p \"$MAGDB\"\n",
    "XTRAFILES=\"/scratch3/workspace/nikea_ulrich_uml_edu-gtdb/annotation/${SAMPLENAME}\"\n",
    "mkdir -p \"$XTRAFILES\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "SAMPLELIST=\"032024_${SAMPLENAME}_sampleids.txt\"\n",
    "\n",
    "\n",
    "#concatenate MAGs into 1 file to create a MAG database\n",
    "cat $MAGPATH/*.fa > $MAGDB/\"$SAMPLENAME\"_mags.fsa\n",
    "\n",
    "cd $MAGDB\n",
    "#index MAG database with bowtie2\n",
    "bowtie2-build --large-index --threads 11 \"$SAMPLENAME\"_mags.fsa \"$SAMPLENAME\"_index\n",
    "\n",
    "while IFS= read -r SAMPLEID; do\n",
    "    #align reads to your contigs and collects that in a .sam file\n",
    "    bowtie2 --threads 11 -x \"$SAMPLENAME\"_index -1 $READSPATH/\"${SAMPLEID}\"_host_removed_R1.tagged_filter_ready.fastq.gz -2 $READSPATH/\"${SAMPLEID}\"_host_removed_R2.tagged_filter_ready.fastq.gz -S $XTRAFILES/\"${SAMPLEID}\".sam\n",
    "    #make sure to point it to the index not the FIXEDCON file (-x parameter)\n",
    "    \n",
    "    #converts your sam file to a bam file, but its neither sorted nor indexed, so we use an Anvi'O script to do so:\n",
    "    samtools view -F 4 -b -S $XTRAFILES/\"${SAMPLEID}\".sam -o $WORKDIR/\"${SAMPLEID}\"-RAW.bam\n",
    "   \n",
    "    #index and sort your bam file\n",
    "    anvi-init-bam $WORKDIR/\"${SAMPLEID}\"-RAW.bam -o $WORKDIR/\"${SAMPLEID}\".bam\n",
    "    \n",
    "    rm $WORKDIR/\"${SAMPLEID}\"-RAW.bam\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "echo \"Mapping success!\"\n",
    "\n",
    "#extract stats with CoverM\n",
    "coverm genome \\\n",
    "    -b $WORKDIR/*.bam \\\n",
    "    -s . \\\n",
    "    -m relative_abundance \\\n",
    "    --min-covered-fraction 0 \\\n",
    "    -o $WORKDIR/mapping_rate\n",
    "\n",
    "coverm genome \\\n",
    "    -b $WORKDIR/*.bam \\\n",
    "    -s . \\\n",
    "    -m count covered_fraction \\\n",
    "    --min-covered-fraction 0 \\\n",
    "    -o $WORKDIR/count_table\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "#JOB ID:28171168, 28172108(coverm)\n",
    "#bash script: nikea/COL/bash_scripts/Col_MAG_mapping.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
